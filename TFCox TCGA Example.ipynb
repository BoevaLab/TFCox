{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75530fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, concatenate, Lambda, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop,SGD,Nadam, Adagrad, Adadelta\n",
    "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
    "from tensorflow.keras.initializers import Constant ,Orthogonal, RandomNormal, VarianceScaling, Ones, Zeros\n",
    "from tensorflow.keras.constraints import Constraint, UnitNorm\n",
    "from keras.callbacks import Callback, TerminateOnNaN, ModelCheckpoint\n",
    "from sksurv.metrics import concordance_index_censored as concordance\n",
    "import math\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103e0a1",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d23fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdf = pd.read_csv('processedExpData.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf = pd.read_csv('yData.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb331eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = pd.read_csv('cancerData.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242473d1",
   "metadata": {},
   "source": [
    "### Model and Nested Crossval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the TFCox class\n",
    "\n",
    "class TFCox():\n",
    "    def __init__(self, seed=42,batch_norm=False,l1_ratio=1,lbda=0.0001,\n",
    "                 max_it=50,learn_rate=0.001,stop_if_nan=True,stop_at_value=False, cscore_metric=False,suppress_warnings=True,verbose=0):\n",
    "        \n",
    "        self.max_it = max_it\n",
    "        self.tnan = stop_if_nan\n",
    "        self.tcscore = stop_at_value\n",
    "        self.lr=learn_rate\n",
    "        self.cscore=cscore_metric\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        \n",
    "        self.l1r = l1_ratio\n",
    "        self.lbda=lbda\n",
    "        self.bnorm = batch_norm\n",
    "        self.verbose=verbose\n",
    "        if suppress_warnings == True:\n",
    "            import warnings\n",
    "            warnings.filterwarnings('ignore')\n",
    "       \n",
    "    def coxloss(self, state):\n",
    "        \n",
    "        def loss(y_true, y_pred):  \n",
    "\n",
    "                return -K.mean((y_pred - K.log(tf.math.cumsum(K.exp(y_pred),reverse=True,axis=0)+0.0001))*state,axis=0)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def cscore_metric(self, state):\n",
    "        def loss(y_true,y_pred):\n",
    "            con = 0\n",
    "            dis = 0\n",
    "            for a in range(len(y_pred)):\n",
    "                for b in range(a+1,len(y_pred)):                                       \n",
    "                        if (y_pred[a]>y_pred[b])  & (y_pred[a]*state[a]!=0):\n",
    "                            con+=1\n",
    "                            \n",
    "                        elif (y_pred[a]<y_pred[b])  & (y_pred[a]*state[a]!=0):\n",
    "                            dis+=1\n",
    "            return     con/(con+dis)\n",
    "        return loss\n",
    " \n",
    "    \n",
    "    def fit(self, X,state,time):\n",
    "        from tensorflow.python.framework.ops import disable_eager_execution\n",
    "        disable_eager_execution()\n",
    "        K.clear_session()\n",
    "       \n",
    "        \n",
    "        \n",
    "        self.time = np.array(time)  \n",
    "        self.newindex = pd.DataFrame(self.time).sort_values(0).index\n",
    "        self.X = (pd.DataFrame(np.array(X)).reindex(self.newindex))                      \n",
    "        self.state = np.array(pd.DataFrame(np.array(state)).reindex(self.newindex))\n",
    "        self.time  = np.array(pd.DataFrame(np.array(time)).reindex(self.newindex))                       \n",
    "        inputsx = Input(shape=(self.X.shape[1],)) \n",
    "        state = Input(shape=(1,))\n",
    "        \n",
    "        if self.bnorm==True:\n",
    "            out = BatchNormalization()(inputsx)\n",
    "            out = Dense(1,activation='linear',\n",
    "                    kernel_regularizer=l1_l2(self.lbda*self.l1r,self.lbda*(1-self.l1r)),\n",
    "                   use_bias=False)(out)\n",
    "        else:\n",
    "            out = Dense(1,activation='linear',\n",
    "                    kernel_regularizer=l1_l2(self.lbda*self.l1r,self.lbda*(1-self.l1r)),\n",
    "                   use_bias=False)(inputsx)\n",
    "\n",
    "        \n",
    "        model = Model(inputs=[inputsx, state], outputs=out)\n",
    "        if (self.tcscore != False) or (self.cscore==True) :\n",
    "            model.compile(optimizer=Adam(self.lr) ,\n",
    "                          loss=self.coxloss(state) , metrics=[self.cscore_metric(state)],\n",
    "                          experimental_run_tf_function=False)\n",
    "        else:\n",
    "            model.compile(optimizer=Adam(self.lr) ,\n",
    "                          loss=self.coxloss(state) ,\n",
    "                          experimental_run_tf_function=False)\n",
    "        \n",
    "        self.model=model\n",
    "        if self.verbose==1:\n",
    "            print(self.model.summary())\n",
    "\n",
    "        self.loss_history_ = []\n",
    "        for its in range(self.max_it):\n",
    "            self.temp_weights = self.model.get_weights()\n",
    "           \n",
    "            tr = self.model.train_on_batch([self.X, self.state],np.zeros(self.state.shape))\n",
    "           \n",
    "            self.loss_history_.append(tr) \n",
    "            \n",
    "            if self.verbose == 1:\n",
    "                if (self.tcscore != False) or (self.cscore==True) :\n",
    "                    print('loss:', self.loss_history_[-1][0],' C-score: ',self.loss_history_[-1][1] )\n",
    "                else:\n",
    "                    print('loss:', self.loss_history_[-1] )\n",
    "            \n",
    "            if self.tcscore != False:\n",
    "                if self.loss_history_[-1][1]>=self.tcscore:\n",
    "                    print('Terminated early because concordance >=' +str(self.tcscore)+ ' as set by stop_at_value flag.')\n",
    "                    break\n",
    "            if (self.tcscore != False) or (self.cscore==True) :\n",
    "                if (math.isnan(self.loss_history_[-1][0]) or math.isinf(self.loss_history_[-1][0])) and self.tnan:\n",
    "                    self.model.set_weights(self.temp_weights)\n",
    "                    print('Terminated because weights == nan or inf, reverted to last valid weight set')\n",
    "                    break\n",
    "            else:\n",
    "                if (math.isnan(self.loss_history_[-1]) or math.isinf(self.loss_history_[-1])) and self.tnan:\n",
    "                    self.model.set_weights(self.temp_weights)\n",
    "                    print('Terminated because weights == nan or inf, reverted to last valid weight set')\n",
    "                    break\n",
    "            \n",
    "        self.beta_ = self.model.get_weights()[-1]\n",
    "\n",
    "    def predict(self,X):\n",
    "        preds = self.model.predict([X,np.zeros(len(X))])\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a function that runs stratified nested shuffle splits using the TFCox class\n",
    "\n",
    "def nestedshuffle(lbda=[0.2], l1_r=1 ,outloop=5,inloop=5,verbose=1):\n",
    "    i=0\n",
    "    np.random.seed(42)\n",
    "    t0=time.time()\n",
    "    index_map = pd.DataFrame(range(len(Xdf)),index=Xdf.index)\n",
    "\n",
    "    outres_train = {}\n",
    "    outres = {}\n",
    "    inner_best = {}\n",
    "    inner_best_train={}\n",
    "    inner_var = {}\n",
    "    errors = {}\n",
    "    preds={}\n",
    "    weights={}\n",
    "    timeO = {}\n",
    "    \n",
    "       \n",
    "    \n",
    "    for out in range(outloop):\n",
    "        np.random.seed(out)\n",
    "        t1=time.time()\n",
    "\n",
    "        totres_train = pd.DataFrame()\n",
    "        totres = pd.DataFrame()\n",
    "        totres_var = pd.DataFrame()\n",
    "        idx=[]\n",
    "        for cnc in list(cancer):\n",
    "            for st in [0,1]:\n",
    "\n",
    "                idx.extend(index_map.loc[ np.random.choice(ydf[(ydf['vital_status']==st) & (cancer[cnc]==1)].index, \n",
    "                                        size=int(0.8*len(ydf[(ydf['vital_status']==st) & (cancer[cnc]==1)])),replace=False)][0].tolist())\n",
    "\n",
    "\n",
    "        idx = np.sort(np.ravel(np.array(idx)))\n",
    "\n",
    "        SS = StandardScaler()\n",
    "        X_train = Xdf.iloc[idx,:]\n",
    "        X_train  = pd.DataFrame(SS.fit_transform(X_train),index=X_train.index,columns=X_train.columns)\n",
    "        X_test = Xdf.iloc[[x for x in range(len(Xdf)) if x not in idx],:]\n",
    "        X_test  = pd.DataFrame(SS.transform(X_test),index=X_test.index,columns=X_test.columns)\n",
    "        y_train = ydf.iloc[idx,:]\n",
    "        y_test = ydf.iloc[[x for x in range(len(Xdf)) if x not in idx],:]\n",
    "        can_train = cancer.iloc[idx,:]\n",
    "        can_test = cancer.iloc[[x for x in range(len(Xdf)) if x not in idx],:]\n",
    "\n",
    "        \n",
    "        for lb in lbda:\n",
    "            \n",
    "            t1=time.time()\n",
    "            results = pd.DataFrame()\n",
    "            trainresults = pd.DataFrame()\n",
    "            index_map2 = pd.DataFrame(range(len(X_train)),index=X_train.index)\n",
    "            for b in range(inloop):\n",
    "                t2=time.time()\n",
    "                K.clear_session()\n",
    "                np.random.seed(b)\n",
    "\n",
    "                idx2 = []\n",
    "                for cnc in list(cancer):\n",
    "                    for st in [0,1]:\n",
    "\n",
    "                        idx2.extend(index_map2.loc[ np.random.choice(y_train[(y_train['vital_status']==st) & (can_train[cnc]==1)].index, \n",
    "                                                size=int(0.75*len(y_train[(y_train['vital_status']==st) & (can_train[cnc]==1)])),replace=False)][0].tolist())\n",
    "\n",
    "\n",
    "                idx2 = np.sort(np.ravel(np.array(idx2)))\n",
    "                SS = StandardScaler()\n",
    "                X_train2 = X_train.iloc[idx2,:]\n",
    "\n",
    "                X_train2  = pd.DataFrame(SS.fit_transform(X_train2),index=X_train2.index,columns=X_train2.columns)\n",
    "                X_test2 = X_train.iloc[[x for x in range(len(X_train)) if x not in idx2],:]\n",
    "                X_test2  = pd.DataFrame(SS.transform(X_test2),index=X_test2.index,columns=X_test2.columns)\n",
    "                y_train2 = y_train.iloc[idx2,:]\n",
    "                y_test2 = y_train.iloc[[x for x in range(len(X_train)) if x not in idx2],:]\n",
    "                can_train2 = can_train.iloc[idx2,:]\n",
    "                can_test2 = can_train.iloc[[x for x in range(len(X_train)) if x not in idx2],:]\n",
    "\n",
    "                resdict = {}\n",
    "                trainresdict = {}\n",
    "                for a in list(cancer):\n",
    "\n",
    "                    Xt2 = X_train2[can_train2[a]==1]\n",
    "                    Xts2 = X_test2[can_test2[a]==1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    K.clear_session()\n",
    "\n",
    "\n",
    "                    model = TFCox(lbda = lb,l1_ratio=l1_r,verbose=verbose)\n",
    "\n",
    "\n",
    "                    model.fit(Xt2,y_train2['vital_status'][can_train2[a]==1],y_train2['time'][can_train2[a]==1])\n",
    "\n",
    "\n",
    "                    train_pred =  model.predict(Xt2).flatten()\n",
    "                    pred = model.predict(Xts2).flatten()\n",
    "\n",
    "\n",
    "                    resdict[a] = pred\n",
    "                    trainresdict[a] = train_pred\n",
    "\n",
    "                res = pd.DataFrame()\n",
    "                trainres = pd.DataFrame()\n",
    "\n",
    "                for a in list(cancer):\n",
    "                  #  print(trainresdict[a].shape)\n",
    "                   # print(y_train2['vital_status'][can_train2[a]==1].astype('bool').shape)\n",
    "                    try:\n",
    "\n",
    "                        trainres.loc[a,0]= concordance(y_train2['vital_status'][can_train2[a]==1].astype('bool'),y_train2['time'][can_train2[a]==1],trainresdict[a])[0]\n",
    "                    except:\n",
    "\n",
    "                        trainres.loc[a,0] = 'fail'\n",
    "\n",
    "                    try:\n",
    "                        res.loc[a,0]= concordance(y_test2['vital_status'][can_test2[a]==1].astype('bool'),y_test2['time'][can_test2[a]==1],resdict[a])[0]\n",
    "\n",
    "                    except:\n",
    "                        res.loc[a,0] = 'fail'\n",
    "\n",
    "\n",
    "                print(i,'/',len(lbda) *outloop*(inloop+1) )\n",
    "                print((time.time()-t0)/60,(time.time()-t1)/60,(time.time()-t2)/60)\n",
    "                results[str(b)] = res[0]\n",
    "                trainresults[str(b)] = trainres[0]\n",
    "                i+=1\n",
    "\n",
    "            totres_var[frozenset({'lambda':lb}.items())] = results.var(1)\n",
    "            totres[frozenset({'lambda':lb}.items())] = results.mean(1)\n",
    "            totres_train[frozenset({'lambda':lb}.items())] = trainresults.mean(1)\n",
    "\n",
    "\n",
    "        inner_best[out] = totres\n",
    "        inner_best_train[out] = totres_train\n",
    "        inner_var[out] = totres_var\n",
    "        outres[out] = pd.DataFrame()\n",
    "        outres_train[out] = pd.DataFrame()\n",
    "        timeO[out] = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        \n",
    "        for prms in list(inner_best[out]):\n",
    "            K.clear_session()\n",
    "            params = dict(prms)\n",
    "\n",
    "\n",
    "            resdict = {}\n",
    "            trainresdict = {}\n",
    "            for a in list(cancer):\n",
    "            \n",
    "                Xt = X_train[can_train[a]==1]\n",
    "                Xts = X_test[can_test[a]==1]\n",
    "                \n",
    "                \n",
    "                t5=time.time()\n",
    "             \n",
    "\n",
    "\n",
    "                K.clear_session()\n",
    "\n",
    "                model = TFCox(lbda = params['lambda'],l1_ratio=l1_r,verbose=verbose)\n",
    "\n",
    "\n",
    "                model.fit(Xt,y_train['vital_status'][can_train[a]==1],y_train['time'][can_train[a]==1])\n",
    "\n",
    "\n",
    "                train_pred =  model.predict(Xt).flatten()\n",
    "                pred = model.predict(Xts).flatten()\n",
    "\n",
    "\n",
    "                resdict[a] = pred\n",
    "                trainresdict[a] = train_pred\n",
    "\n",
    "                timeO[out].loc[a,frozenset(params.items())] = time.time()-t5\n",
    "                \n",
    "            res = pd.DataFrame()\n",
    "            trainres = pd.DataFrame()\n",
    "            for a in list(cancer):\n",
    "                try:\n",
    "\n",
    "                    trainres.loc[a,0]= concordance(y_train['vital_status'][can_train[a]==1].astype('bool'),y_train['time'][can_train[a]==1],trainresdict[a])[0]\n",
    "                except:\n",
    "\n",
    "                    trainres.loc[a,0] = 'fail'\n",
    "                try:\n",
    "                    res.loc[a,0]= concordance(y_test['vital_status'][can_test[a]==1].astype('bool'),y_test['time'][can_test[a]==1],resdict[a])[0]\n",
    "\n",
    "                except:\n",
    "                    res.loc[a,0] = 'fail'\n",
    "\n",
    "            print(i,'/',len(lbda) *outloop*(inloop+1) )\n",
    "            print((time.time()-t0)/60,(time.time()-t1)/60,(time.time()-t2)/60)\n",
    "            i+=1\n",
    "            outres[out][frozenset(params.items())] = res[0]\n",
    "            outres_train[out][frozenset(params.items())] = trainres[0]\n",
    "          \n",
    "    return outres , outres_train,inner_best,inner_best_train,inner_var,timeO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbafe2",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223a20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the geometric range of lambdas\n",
    "vals = [float(np.format_float_positional(1 * 0.75**i, precision=2, unique=False, fractional=False, trim='k')) for i in range(25)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b112e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested shuffle splits with LASSO Regularization\n",
    "lassoO1,lassoO2,lassoI1,lassoI2,lassovar,lassotime= nestedshuffle(lbda=vals,l1_r=1 ,outloop=5, inloop=5,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b063881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested shuffle splits with elastic-net l1_ratio=0.5 Regularization\n",
    "elnetO1,elnetO2,elnetI1,elnetI2,elnetvar,elnettime= nestedshuffle(lbda=vals,l1_r=0.5 ,outloop=5, inloop=5,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71699b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loop finds the lambda selected by the inner loop and returns the concordance from the outer loop. \n",
    "lassores = pd.DataFrame()\n",
    "numloops=5\n",
    "for b in range(numloops):\n",
    "    for a in list(lassoI1[b].index):\n",
    "        \n",
    "        \n",
    "        lassores.loc[a,b] =  lassoO1[b][lassoI1[b].idxmax(1)[a]][a]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same as above but for elastic net\n",
    "elnetres = pd.DataFrame()\n",
    "numloops=5\n",
    "for b in range(numloops):\n",
    "    for a in list(elnetI1[b].index):\n",
    "        \n",
    "        \n",
    "        elnetres.loc[a,b] =  elnetO1[b][elnetI1[b].idxmax(1)[a]][a]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The overall mean outer loop results for the lasso model\n",
    "lassores.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The overall mean outer loop results for the lasso model\n",
    "elnetres.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c66230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanpython",
   "language": "python",
   "name": "cleanpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
